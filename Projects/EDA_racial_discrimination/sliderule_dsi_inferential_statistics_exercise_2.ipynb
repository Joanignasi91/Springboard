{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Examining Racial Discrimination in the US Job Market\n",
    "\n",
    "### Background\n",
    "Racial discrimination continues to be pervasive in cultures throughout the world. Researchers examined the level of racial discrimination in the United States labor market by randomly assigning identical résumés to black-sounding or white-sounding names and observing the impact on requests for interviews from employers.\n",
    "\n",
    "### Data\n",
    "In the dataset provided, each row represents a resume. The 'race' column has two values, 'b' and 'w', indicating black-sounding and white-sounding. The column 'call' has two values, 1 and 0, indicating whether the resume received a call from employers or not.\n",
    "\n",
    "Note that the 'b' and 'w' values in race are assigned randomly to the resumes when presented to the employer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exercises\n",
    "You will perform a statistical analysis to establish whether race has a significant impact on the rate of callbacks for resumes.\n",
    "\n",
    "Answer the following questions **in this notebook below and submit to your Github account**. \n",
    "\n",
    "   1. What test is appropriate for this problem? Does CLT apply?\n",
    "   2. What are the null and alternate hypotheses?\n",
    "   3. Compute margin of error, confidence interval, and p-value. Try using both the bootstrapping and the frequentist statistical approaches.\n",
    "   4. Write a story describing the statistical significance in the context or the original problem.\n",
    "   5. Does your analysis mean that race/name is the most important factor in callback success? Why or why not? If not, how would you amend your analysis?\n",
    "\n",
    "You can include written notes in notebook cells using Markdown: \n",
    "   - In the control panel at the top, choose Cell > Cell Type > Markdown\n",
    "   - Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "\n",
    "#### Resources\n",
    "+ Experiment information and data source: http://www.povertyactionlab.org/evaluation/discrimination-job-market-united-states\n",
    "+ Scipy statistical methods: http://docs.scipy.org/doc/scipy/reference/stats.html \n",
    "+ Markdown syntax: http://nestacms.com/docs/creating-content/markdown-cheat-sheet\n",
    "+ Formulas for the Bernoulli distribution: https://en.wikipedia.org/wiki/Bernoulli_distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.io.stata.read_stata('data/us_job_market_discrimination.dta')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p>Your answers to Q1 and Q2 here</p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total white sounding names 2435 is larger than 30\n",
      "Total calls for whites 235.0 as well as non-calls 2200.0 are greater than 10\n",
      "Total black sounding names 2435 is larger than 30\n",
      "Total calls for blacks 157.0 as well as non-calls 2278.0 are greater than 10\n"
     ]
    }
   ],
   "source": [
    "# 1 What test is appropriate for this problem? Does CLT apply?\n",
    "print('Total white sounding names', len(data[data.race=='w']), 'is larger than 30')\n",
    "print('Total calls for whites', sum(data[data.race=='w'].call), 'as well as non-calls', len(data[data.race=='w']) - sum(data[data.race=='w'].call), 'are greater than 10')\n",
    "print('Total black sounding names', len(data[data.race=='b']), 'is larger than 30')\n",
    "print('Total calls for blacks', sum(data[data.race=='b'].call), 'as well as non-calls', len(data[data.race=='b']) - sum(data[data.race=='b'].call), 'are greater than 10')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>As the sizes of each sample, each split equally between white and black sounding names at 2435 elements are very large.</p>\n",
    "<p>A z-test would be appropriate as according to the central theorem in a sample that is well above 30 elements using the standard error of the sample would provide a good estimate for the standard deviation of the population.</p>\n",
    "<p>As data['call'] is a Bernoulli distribution 1 representing success in getting a callback and 0 a failure, the number of elements for failure or success cases for both distributions are well above 10, also following the central limit theorem.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>2. What are the null and alternate hypotheses?</p>\n",
    "<p>The null hypothesis would be that individuals with black sounding names get proportionally as many callbacks as ones with white sounding names, and the alternative hypothesis would be that there is a difference in proportional number of callbacks.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We split the data by race\n",
    "w = data[data.race=='w']\n",
    "b = data[data.race=='b']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p value using the bootstrap approach is 0.0031 therefore we reject the null hypothesis and accept the alternative\n",
      "hypothesis that the callback rate between black and white sounding names is different\n"
     ]
    }
   ],
   "source": [
    "# Your solution to Q3 here\n",
    "# Using the bootstrap approach\n",
    "def draw_bs_replicates(data, func, size=1):\n",
    "    \"\"\"Draw bootstrap replicates.\"\"\"\n",
    "\n",
    "    # Initialize array of replicates: bs_replicates\n",
    "    bs_replicates = np.empty(size)\n",
    "\n",
    "    # Generate replicates\n",
    "    for i in range(size):\n",
    "        bs_replicates[i] = func(np.random.choice(data, size=len(data)))\n",
    "\n",
    "    return bs_replicates\n",
    "mean_prop = np.mean(data.call)\n",
    "bootstrap_white = draw_bs_replicates(w.call, np.mean, size=10000)\n",
    "bootstrap_black = draw_bs_replicates(b.call, np.mean, size=10000)\n",
    "bootstrap_replicates = np.absolute(bootstrap_white - bootstrap_black)\n",
    "translated_white = w.call - np.mean(w.call) + mean_prop\n",
    "translated_black = b.call - np.mean(b.call) + mean_prop\n",
    "translated_bootstrap_white = draw_bs_replicates(translated_white, np.mean, size=10000)\n",
    "translated_bootstrap_black = draw_bs_replicates(translated_black, np.mean, size=10000)\n",
    "translated_bootstrap_replicates = np.absolute(translated_bootstrap_white - translated_bootstrap_black)\n",
    "\n",
    "p = np.sum(bootstrap_replicates <= translated_bootstrap_replicates) / 10000\n",
    "print('The p value using the bootstrap approach is', p, 'therefore we reject the null hypothesis and accept the alternative')\n",
    "print('hypothesis that the callback rate between black and white sounding names is different')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The margin of error is +- 0.015255126027 at a 95% confidence level\n"
     ]
    }
   ],
   "source": [
    "# Using the frequentist approach\n",
    "# Since we don't have the standard deviation of the population and our samples are above 30 elements we can estimate the margin of \n",
    "# error by multiplying the standard error of the sample proportion by the z factor.\n",
    "std_err_diff = np.sqrt(np.mean(w.call)*(1-np.mean(w.call))/len(w)+np.mean(b.call)*(1-np.mean(b.call))/(len(b)))\n",
    "# We now have to provide an appropriate z-value for the most commonly used 95% confidence level which in this case is two tailed\n",
    "# as we are interested in differences in either direction\n",
    "conf_95 = stats.norm.ppf(0.975)\n",
    "# Therefore the margin of error is given by the standard error by the z factor at that confidence level\n",
    "mrg_err_diff = conf_95*std_err_diff\n",
    "print('The margin of error is +-', mrg_err_diff, 'at a 95% confidence level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The margin of error for the difference in callback proportions in the two samples is approximately 1.5% at a 95% confidence level. Such a low margin of error bellow 2% suggests the results of the study are close to the true value.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The cofidence interval is [0.016777728828047841, 0.047287980882073311] at a 95% confidence level\n"
     ]
    }
   ],
   "source": [
    "# We calculate the confidence interval by adding and substracting the margin of error to the sample proportion\n",
    "conf_int_diff = []\n",
    "conf_int_diff.append(np.mean(w.call)-np.mean(b.call)-mrg_err_diff)\n",
    "conf_int_diff.append(np.mean(w.call)-np.mean(b.call)+mrg_err_diff)\n",
    "print('The cofidence interval is', conf_int_diff, 'at a 95% confidence level')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The resulting confidence interval suggests resumes with white sounding names received a callback between 1.7%(2s.v) and 4.7%(2s.v) more often than résumés with black sounding names at a 95% confidence level</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The p value using the frequentist approach is 3.9838854095e-05 therefore we reject the null hypothesis and accept the\n",
      "alternative hypothesis that the callback rate between black and white sounding names is different\n"
     ]
    }
   ],
   "source": [
    "# To calculate the p value we substact the target proportion from the difference in sample proportions and we divide it by the \n",
    "# standard error if both samples had the same rate of callbacks.\n",
    "# The target proportion in this case 0 as the null hypothesis is that both samples would receive the same proportion of callbacks\n",
    "# We calculate the standard proportion for both samples by adding the total number of successes of both samples and dividing them\n",
    "# by the total number of both samples.\n",
    "new_prop = (sum(w.call)+sum(b.call))/(len(w.call)+len(b.call))\n",
    "z = (np.mean(b.call)-np.mean(w.call)-0)/np.sqrt(2*(new_prop*(1-new_prop))/len(w.call))\n",
    "# we calculate the p value as twice the value of the area to the left of the negative of z standard deviations from 0 as we count\n",
    "# we multiply it by 2 as the alternative hypothesis is that there is a difference in either direction away from the mean\n",
    "p = 2 * stats.norm.cdf(z)\n",
    "print('The p value using the frequentist approach is', p, 'therefore we reject the null hypothesis and accept the')\n",
    "print('alternative hypothesis that the callback rate between black and white sounding names is different')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>The p value being well bellow 0.05 means we reject the null hypothesis and accept the alternative hypothesis</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"span5 alert alert-success\">\n",
    "<p> Your answers to Q4 and Q5 here </p>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>4. Write a story describing the statistical significance in the context or the original problem</p>\n",
    "<p>&nbsp;The hypothesis test on 4870 resumes with half of them being assigned randomly black sounding names and the other half white sounding names found that race was a factor in determining the rate of callbacks in a resume.</p>\n",
    "<p>Because the resumes were randomly assigned white and black sounding names and there were a very large amount of each type of resume with a high rate of successful and unsuccessful callbacks for each type of resume, thus the sample followed the central limit theorem.</p>\n",
    "<p>Despite the high number resumes it could be possible that by chance the selection had been squewed thus making the results unreliable.</p>\n",
    "<p>We will perform a Wasserstein distance test on the two distributions to determine the dissimilarity between the two.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dissimilarity in the two distributions on occupspecific feature is above 0.2 at 3.03655030801\n",
      "Average dissimilarity rate 0.053790333452\n"
     ]
    }
   ],
   "source": [
    "data_keys = list(data.keys())\n",
    "new_df = data.copy()\n",
    "dist_list = []\n",
    "# we simply factorise the data as it is not important which number represents which category in this case\n",
    "for i in data_keys:\n",
    "    if data[i].dtype == 'object':\n",
    "        new_df[i] = pd.factorize(new_df[i])[0]\n",
    "# we fill all the nan values with 0 to avoid errors though this will affect the accuracy of the results somewhat\n",
    "new_df = new_df.fillna(0)\n",
    "# we divide the factorised data in race groups a prevoiusly done\n",
    "d0 = new_df[new_df.race==0]\n",
    "d1 = new_df[new_df.race==1]\n",
    "# we drop the race and firstname columns to improve accuracy in the comparison as they are purposefuly different in the context of\n",
    "# this study\n",
    "d0 = d0.drop(['race', 'firstname'], axis=1)\n",
    "d1 = d1.drop(['race', 'firstname'], axis=1)\n",
    "data_keys.remove('race')\n",
    "data_keys.remove('firstname')\n",
    "# We perform a Wasserstein distance test to find the dissimilarity between features of the two distributions\n",
    "# We found EOF errors when we first tried this part of the code so we will try except them\n",
    "import sys\n",
    "try:\n",
    "    for i in data_keys:\n",
    "        dist_list.append(stats.wasserstein_distance(d0[i], d1[i]))\n",
    "        if stats.wasserstein_distance(d0[i], d1[i]) > 0.2:\n",
    "            data_keys = list(data.keys())\n",
    "            print('Dissimilarity in the two distributions on', i, 'feature is above 0.2 at', stats.wasserstein_distance(d0[i], d1[i]))\n",
    "    \n",
    "except:\n",
    "    print('unexpected_error', sys.exc_info())\n",
    "print('Average dissimilarity rate', np.mean(dist_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>From this result we see the rate of dissimilarity mostly insignificant at only 0.05 dominated by the occupspecific feature as an extreme outlier, we couldn't find in the original \n",
    "  <a href=\"https://www.nber.org/papers/w9873.pdf\">paper</a> documentation on the data of the study so we can't tell for sure what that feature means at the moment.\n",
    "</p>\n",
    "<p> We can thus be certain that race/name was a factor in determining callback success, though we should be careful when applying the conclusions of this study to discuss race relations in the US as a whole, as this study only covered the populations of the Boston and Chicago urban areas.</p>\n",
    "<p> A meta-study covering more diverse types of populations throughout the country that better represent the makeup of the country would be necessary in order to make the conclusions more applicable to the country as a whole.</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>5. Does your analysis mean that race/name is the most important factor in callback success? Why or why not? If not, how would you amend your analysis?</p>\n",
    "<p>The results of the analysis only determine that first-names associated to black or white people are a factor in determining callback success.</p>\n",
    "<p>It being the most significant factor is a completely different question which would require analyzing all other possible factors such as gender, education level, years of experience, etc... Which we did not study, thus we can't determine that race is the most important factor in determining callback rate.</p>\n",
    "<p>To determine the most significant factor in determining callback success we would have to perform tests on all possible factors that could affect callback success and compare which one is more significant.</p>\n",
    "<p>We would also have to contend with the possibility that other factors that affected callback success were also not recorded in the study.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
